{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/face_emotion/face_classification_modi/src\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bash_kernel\n",
      "  Downloading https://files.pythonhosted.org/packages/93/7a/50edf4a05663429b4ca6e789a10fd3d1b581ec869a036b9d7d9ba1ffc34a/bash_kernel-0.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pexpect>=4.0 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from bash_kernel) (4.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from pexpect>=4.0->bash_kernel) (0.6.0)\n",
      "Installing collected packages: bash-kernel\n",
      "Successfully installed bash-kernel-0.7.1\n",
      "Installing IPython kernel spec\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /root/.local/share/jupyter/kernels/face_emo_cnn/bin/activate\n",
    "\n",
    "pip install bash_kernel\n",
    "python -m bash_kernel.install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling numpy-1.16.4:\n",
      "  Successfully uninstalled numpy-1.16.4\n",
      "Collecting scipy==1.0.0 (from -r ../REQUIREMENTS.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/83/6aed4f564f3f5d338fd3c642f33d5ded0fc577da5f9a7d85ed6ba23c5d51/scipy-1.0.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: tensorflow-gpu==1.12.0 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from -r ../REQUIREMENTS.txt (line 2)) (1.12.0)\n",
      "Collecting keras==2.0.5 (from -r ../REQUIREMENTS.txt (line 3))\n",
      "Requirement already satisfied: pandas==0.19.1 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from -r ../REQUIREMENTS.txt (line 4)) (0.19.1)\n",
      "Collecting numpy==1.14.5 (from -r ../REQUIREMENTS.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/43/17/cd9fa14492dbef2aaf22622db79dba087c10f125473e730cda2f2019c40b/numpy-1.14.5-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: h5py==2.7.0 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from -r ../REQUIREMENTS.txt (line 6)) (2.7.0)\n",
      "Requirement already satisfied: statistics in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from -r ../REQUIREMENTS.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: opencv-python in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from -r ../REQUIREMENTS.txt (line 8)) (4.1.0.25)\n",
      "Requirement already satisfied: astor>=0.6.0 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (0.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (3.8.0)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (1.12.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (1.21.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (0.33.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: theano in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from keras==2.0.5->-r ../REQUIREMENTS.txt (line 3)) (1.0.4)\n",
      "Requirement already satisfied: pyyaml in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from keras==2.0.5->-r ../REQUIREMENTS.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: pytz>=2011k in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from pandas==0.19.1->-r ../REQUIREMENTS.txt (line 4)) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from pandas==0.19.1->-r ../REQUIREMENTS.txt (line 4)) (2.8.0)\n",
      "Requirement already satisfied: docutils>=0.3 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from statistics->-r ../REQUIREMENTS.txt (line 7)) (0.14)\n",
      "Requirement already satisfied: setuptools in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (41.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (0.15.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0->-r ../REQUIREMENTS.txt (line 2)) (3.1.1)\n",
      "Installing collected packages: numpy, scipy, keras\n",
      "Successfully installed keras-2.0.5 numpy-1.14.5 scipy-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping scipy as it is not installed.\n",
      "WARNING: Skipping keras as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# import Tnesorflow and other libraries\n",
    "source /root/.local/share/jupyter/kernels/face_emo_cnn/bin/activate\n",
    "pip uninstall -y scipy\n",
    "pip uninstall -y numpy\n",
    "pip uninstall -y keras\n",
    "pip uninstall -y tensorflow\n",
    "pip install -r ../REQUIREMENTS.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'face_classification'...\n",
      "remote: Enumerating objects: 170, done.\u001b[K\n",
      "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 887 (delta 97), reused 158 (delta 92), pack-reused 717\u001b[K\n",
      "Receiving objects: 100% (887/887), 121.29 MiB | 11.37 MiB/s, done.\n",
      "Resolving deltas: 100% (485/485), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/oarriaga/face_classification.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 984\r\n",
      "drwxr-xr-x 7 root root    239 Jun 19 16:04 .\r\n",
      "drwxr-xr-x 4 root root    101 Jun 19 16:05 ..\r\n",
      "drwxr-xr-x 8 root root    211 Jun 19 16:04 .git\r\n",
      "-rw-r--r-- 1 root root    120 Jun 19 16:04 .gitignore\r\n",
      "-rw-r--r-- 1 root root    532 Jun 19 16:04 Dockerfile\r\n",
      "-rw-r--r-- 1 root root   1064 Jun 19 16:04 LICENSE\r\n",
      "-rw-r--r-- 1 root root   2246 Jun 19 16:04 README.md\r\n",
      "-rw-r--r-- 1 root root    104 Jun 19 16:04 REQUIREMENTS.txt\r\n",
      "drwxr-xr-x 2 root root     32 Jun 19 16:04 datasets\r\n",
      "drwxr-xr-x 2 root root    248 Jun 19 16:04 images\r\n",
      "-rw-r--r-- 1 root root 980831 Jun 19 16:04 report.pdf\r\n",
      "drwxr-xr-x 5 root root   4096 Jun 19 16:04 src\r\n",
      "drwxr-xr-x 5 root root    181 Jun 19 16:04 trained_models\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al face_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To train previous/new models for emotion classification:\n",
    "\n",
    "* Download the fer2013.tar.gz file from [here](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data)\n",
    "\n",
    "* Move the downloaded file to the datasets directory inside this repository.\n",
    "\n",
    "* Untar the file:\n",
    "    tar -xzf fer2013.tar\n",
    "    Run the train_emotion_classification.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading example_submission.csv to {~/.kaggle}/competitions/challenges-in-representation-learning-facial-expression-recognition-challenge\n",
      "  0%|                                               | 0.00/7.01k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 7.01k/7.01k [00:00<00:00, 2.92MB/s]\n",
      "Downloading fer2013.tar.gz to {~/.kaggle}/competitions/challenges-in-representation-learning-facial-expression-recognition-challenge\n",
      " 99%|█████████████████████████████████████▌| 91.0M/92.0M [00:08<00:00, 11.9MB/s]\n",
      "100%|██████████████████████████████████████| 92.0M/92.0M [00:08<00:00, 11.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the fer2013.tar.gz file\n",
    "## setting your kaggle config first\n",
    "## accept rule on kaggle webpage \n",
    "\n",
    "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the downloaded file to the datasets directory inside this repository.\n",
    "\n",
    "# !ls -al face_classification/datasets\n",
    "!mv {~/.kaggle}/competitions/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013.tar.gz face_classification/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_FOLDER='/tf/notebooks/face_emotion/face_classification_modi'\n",
    "\n",
    "os.environ['HOME_FOLDER']='/tf/notebooks/face_emotion/face_classification_modi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fer2013/fer2013.csv\n",
      "fer2013/README\n",
      "fer2013/fer2013.bib\n",
      "fer2013/\n"
     ]
    }
   ],
   "source": [
    "# Untar the file: tar -xzf fer2013.tar \n",
    "\n",
    "!cd {HOME_FOLDER}/datasets && tar -xvzf fer2013.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /root/.local/share/jupyter/kernels/face_emo_cnn/bin/activate\n",
    "# Run the train_emotion_classification.py file\n",
    "\n",
    "cd ${HOME_FOLDER}/src && python3 train_emotion_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "File: train_emotion_classifier.py\n",
    "Author: Octavio Arriaga\n",
    "Email: arriaga.camargo@gmail.com\n",
    "Github: https://github.com/oarriaga\n",
    "Description: Train emotion classification model\n",
    "\"\"\"\n",
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "\n",
    "from models.cnn import mini_XCEPTION\n",
    "from utils.datasets import DataManager\n",
    "from utils.datasets import split_data\n",
    "from utils.preprocessor import preprocess_input\n",
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10000\n",
    "input_shape = (64, 64, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = '../trained_models/emotion_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 06:12:49.803094 139656505165568 deprecation_wrapper.py:119] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0623 06:12:49.806803 139656505165568 deprecation_wrapper.py:119] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:431: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0623 06:12:49.810929 139656505165568 deprecation_wrapper.py:119] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0623 06:12:49.827872 139656505165568 deprecation.py:506] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1190: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0623 06:12:50.132827 139656505165568 deprecation_wrapper.py:119] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3288: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0623 06:12:50.595419 139656505165568 deprecation_wrapper.py:119] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/optimizers.py:699: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0623 06:12:50.617826 139656505165568 deprecation_wrapper.py:119] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2751: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 62, 62, 8)     72          input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 62, 62, 8)     32          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 62, 62, 8)     0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 60, 60, 8)     576         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 60, 60, 8)     32          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 60, 60, 8)     0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCon (None, 60, 60, 16)    200         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 60, 60, 16)    64          separable_conv2d_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 60, 60, 16)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCon (None, 60, 60, 16)    400         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 60, 60, 16)    64          separable_conv2d_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 30, 30, 16)    128         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 30, 30, 16)    0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 30, 30, 16)    64          conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 30, 30, 16)    0           max_pooling2d_1[0][0]            \n",
      "                                                                   batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCon (None, 30, 30, 32)    656         add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 30, 30, 32)    128         separable_conv2d_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 30, 30, 32)    0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCon (None, 30, 30, 32)    1312        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 30, 30, 32)    128         separable_conv2d_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 15, 15, 32)    512         add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 15, 15, 32)    0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 15, 15, 32)    128         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 15, 15, 32)    0           max_pooling2d_2[0][0]            \n",
      "                                                                   batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCon (None, 15, 15, 64)    2336        add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 15, 15, 64)    256         separable_conv2d_5[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 15, 15, 64)    0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCon (None, 15, 15, 64)    4672        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 15, 15, 64)    256         separable_conv2d_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 8, 8, 64)      2048        add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 8, 8, 64)      0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 8, 8, 64)      256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 8, 8, 64)      0           max_pooling2d_3[0][0]            \n",
      "                                                                   batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCon (None, 8, 8, 128)     8768        add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 8, 8, 128)     512         separable_conv2d_7[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 8, 8, 128)     0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCon (None, 8, 8, 128)     17536       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 8, 8, 128)     512         separable_conv2d_8[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 4, 4, 128)     8192        add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 4, 4, 128)     0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 4, 4, 128)     512         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 4, 4, 128)     0           max_pooling2d_4[0][0]            \n",
      "                                                                   batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 4, 4, 7)       8071        add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 7)             0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Activation)         (None, 7)             0           global_average_pooling2d_1[0][0] \n",
      "====================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "____________________________________________________________________________________________________\n",
      "Training dataset: fer2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 06:13:14.033853 139656505165568 deprecation.py:323] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0623 06:13:15.514339 139656505165568 deprecation_wrapper.py:119] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:878: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0623 06:13:15.524165 139656505165568 deprecation.py:506] From /root/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:601: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "device CUDA:4 not supported by XLA service\n\twhile setting up XLA_GPU_JIT device number 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7eedf2f2e69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_faces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                         validation_data=val_data)\n\u001b[0m",
      "\u001b[0;32m~/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    162\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \"\"\"\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/jupyter/kernels/face_emo_cnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: device CUDA:4 not supported by XLA service\n\twhile setting up XLA_GPU_JIT device number 4"
     ]
    }
   ],
   "source": [
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datasets = ['fer2013']\n",
    "for dataset_name in datasets:\n",
    "    print('Training dataset:', dataset_name)\n",
    "\n",
    "    # callbacks\n",
    "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "    csv_logger = CSVLogger(log_file_path, append=False)\n",
    "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "    # loading dataset\n",
    "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
    "    faces, emotions = data_loader.get_data()\n",
    "    faces = preprocess_input(faces)\n",
    "    num_samples, num_classes = emotions.shape\n",
    "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
    "    train_faces, train_emotions = train_data\n",
    "    model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(train_faces) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_emo_cnn",
   "language": "python",
   "name": "face_emo_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
