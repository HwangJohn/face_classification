{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7632\r\n",
      "drwxrwxr-x   3 1005 1000    4096 May  7 01:35 .\r\n",
      "drwxrwxr-x 294 1005 1000   12288 May 13 12:31 ..\r\n",
      "drwxrwxr-x  12 1005 1000     330 May  7 01:36 KETI_MULTIMODAL_0000000012\r\n",
      "-rw-rw-r--   1 1005 1000 6375544 May  7 00:39 KETI_MULTIMODAL_0000000012.mp4\r\n",
      "-rw-rw-r--   1 1005 1000  682740 May  7 00:39 KETI_MULTIMODAL_0000000012_interpolation.json\r\n",
      "-rw-rw-r--   1 1005 1000    1801 May  7 00:39 KETI_MULTIMODAL_0000000012_jiyu.json\r\n",
      "-rw-rw-r--   1 1005 1000    1267 May  7 00:39 KETI_MULTIMODAL_0000000012_jiyu_interpolation.json\r\n",
      "-rw-rw-r--   1 1005 1000   38674 May  7 00:39 KETI_MULTIMODAL_0000000012_roykim1234.json\r\n",
      "-rw-rw-r--   1 1005 1000  681679 May  7 00:39 KETI_MULTIMODAL_0000000012_roykim1234_interpolation.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al /tf/notebooks/datasets/emotion/multi-modal/part1/KETI_MULTIMODAL_0000000012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycodestyle in /root/.local/share/jupyter/kernels/rt-face-detect/lib/python3.5/site-packages (2.5.0)\n",
      "Requirement already satisfied: pycodestyle_magic in /root/.local/share/jupyter/kernels/rt-face-detect/lib/python3.5/site-packages (0.2.5)\n",
      "Collecting flake8\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/76/b915bd28976068a9843bf836b789794aa4a8eb13338b23581005cd9177c0/flake8-3.7.7-py2.py3-none-any.whl (68kB)\n",
      "Collecting entrypoints<0.4.0,>=0.3.0 (from flake8)\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pycodestyle<2.6.0,>=2.5.0 in /root/.local/share/jupyter/kernels/rt-face-detect/lib/python3.5/site-packages (from flake8) (2.5.0)\n",
      "Collecting mccabe<0.7.0,>=0.6.0 (from flake8)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
      "Collecting pyflakes<2.2.0,>=2.1.0 (from flake8)\n",
      "  Downloading https://files.pythonhosted.org/packages/84/f2/ed0ffb887f8138a8fe5a621b8c0bb9598bfb3989e029f6c6a85ee66628ee/pyflakes-2.1.1-py2.py3-none-any.whl (59kB)\n",
      "Installing collected packages: entrypoints, mccabe, pyflakes, flake8\n",
      "Successfully installed entrypoints-0.3 flake8-3.7.7 mccabe-0.6.1 pyflakes-2.1.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "source /root/.local/share/jupyter/kernels/rt-face-detect/bin/activate\n",
    "\n",
    "pip install pycodestyle pycodestyle_magic\n",
    "pip install flake8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공통 전처리 부분 (Frame 단위)\n",
    "\n",
    "#### inputs:\n",
    "* 태깅파일: ~_interpolation.json\n",
    "* 이미지파일: ~KM_0000000000.jpg\n",
    "* 감정종류: 8가지 ('happiness', 'afraid', 'neutral', 'surprise', 'sadness', 'contempt', 'anger', 'disgust')\n",
    "    * 예시: {'happiness': 0, 'afraid': 0, 'neutral': 10, 'surprise': 0, 'sadness': 0, 'contempt': 0, 'anger': 0, 'disgust': 0} 일 경우 'neutral'이 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import io\n",
    "import numpy as np\n",
    "import operator\n",
    "import collections\n",
    "import base64\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from IPython.display import HTML\n",
    "\n",
    "# multi-modal 데이터셋 다운로드 위치 입력\n",
    "\n",
    "# 입력 zip파일의 part 번호\n",
    "part_num = '4'\n",
    "\n",
    "# input 폴더\n",
    "base_folder = '/tf/notebooks/datasets/emotion/multi-modal/part'+part_num+'/'\n",
    "\n",
    "# output 파일경로\n",
    "prep_trainset_path='../datasets/kor_multi_modal/prep_part'+part_num+'.csv'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태깅설명: http://www.aihub.or.kr/content/555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맵핑\n",
    "def get_tagging_info(json_loaded, img_path_list):\n",
    "    train_data = []\n",
    "    for shot_info_idx in range(len(json_loaded[\"shot_infos\"])):\n",
    "        for visual_info_idx in range(len(json_loaded[\"shot_infos\"][shot_info_idx][\"visual_infos\"])):\n",
    "            img_path = json_loaded[\"shot_infos\"][shot_info_idx][\"visual_infos\"][visual_info_idx][\"image_id\"]\n",
    "            if json_loaded[\"shot_infos\"][shot_info_idx][\"visual_infos\"][visual_info_idx][\"persons\"] != []:\n",
    "                for person_info_idx in range(len(json_loaded[\"shot_infos\"][shot_info_idx][\"visual_infos\"][visual_info_idx][\"persons\"])):\n",
    "                    if json_loaded[\"shot_infos\"][shot_info_idx][\"visual_infos\"][visual_info_idx][\"persons\"][person_info_idx][\"person_info\"][\"emotion\"] != []:\n",
    "                        person = json_loaded[\"shot_infos\"][shot_info_idx][\"visual_infos\"][visual_info_idx][\"persons\"][person_info_idx]\n",
    "                        face_rect = person['person_info']['face_rect']\n",
    "                        emotion = person[\"person_info\"][\"emotion\"]\n",
    "\n",
    "                        # 수치가 가장 큰 감정 선택\n",
    "                        max_emo = max(emotion.items(), key=operator.itemgetter(1))[0]\n",
    "                        \n",
    "                        img_exist_path = [s for s in img_path_list if img_path in s]\n",
    "                        if img_exist_path == []:\n",
    "                            continue\n",
    "                        \n",
    "                        full_img_path = img_exist_path[0]\n",
    "                        \n",
    "                        if full_img_path != []:\n",
    "                            train_data.append({'emotion':max_emo, 'img_path':full_img_path, 'face_rect':face_rect})\n",
    "                                        \n",
    "            \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clip_pathes = glob(base_folder+\"/*\")\n",
    "\n",
    "raw_tag_info = []\n",
    "\n",
    "# tmp_idx = 0                      # 작은 데이터로 테스트 필요할 시 주석처리\n",
    "for video_clip_path in video_clip_pathes:\n",
    "    \n",
    "    # 해당 비디오 클립의 전체 이미지 경로\n",
    "    img_path_list = glob(video_clip_path+\"/*/*/*.jpg\")    \n",
    "\n",
    "    # 해당 비디오 클립의 태깅정보 파일 경로\n",
    "    json_file_name_postfix = video_clip_path.split(\"_\")[-2]+\"_\"+video_clip_path.split(\"_\")[-1]\n",
    "    video_clip_tagging_json_path = glob(os.path.join(video_clip_path, \"*\"+json_file_name_postfix+\"_interpolation.json\"))\n",
    "\n",
    "    with open(video_clip_tagging_json_path[0], 'r') as f:\n",
    "        json_loaded = json.load(f)\n",
    "        \n",
    "    raw_tag_info = raw_tag_info + get_tagging_info(json_loaded, img_path_list)\n",
    "    \n",
    "#     tmp_idx = tmp_idx + 1  # 작은 데이터로 테스트 필요할 시 주석처리\n",
    "#     if tmp_idx > 1:              # 작은 데이터로 테스트 필요할 시 주석처리\n",
    "#         break                       # 작은 데이터로 테스트 필요할 시 주석처리\n",
    "    \n",
    "raw_tag_info_df = pd.DataFrame(raw_tag_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>face_rect</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happiness</td>\n",
       "      <td>{'min_x': 934, 'min_y': 150, 'max_x': 1243, 'm...</td>\n",
       "      <td>/tf/notebooks/datasets/emotion/multi-modal/par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happiness</td>\n",
       "      <td>{'min_x': 932, 'min_y': 150, 'max_x': 1241, 'm...</td>\n",
       "      <td>/tf/notebooks/datasets/emotion/multi-modal/par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happiness</td>\n",
       "      <td>{'min_x': 931, 'min_y': 150, 'max_x': 1240, 'm...</td>\n",
       "      <td>/tf/notebooks/datasets/emotion/multi-modal/par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happiness</td>\n",
       "      <td>{'min_x': 929, 'min_y': 149, 'max_x': 1238, 'm...</td>\n",
       "      <td>/tf/notebooks/datasets/emotion/multi-modal/par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happiness</td>\n",
       "      <td>{'min_x': 927, 'min_y': 149, 'max_x': 1236, 'm...</td>\n",
       "      <td>/tf/notebooks/datasets/emotion/multi-modal/par...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion                                          face_rect  \\\n",
       "0  happiness  {'min_x': 934, 'min_y': 150, 'max_x': 1243, 'm...   \n",
       "1  happiness  {'min_x': 932, 'min_y': 150, 'max_x': 1241, 'm...   \n",
       "2  happiness  {'min_x': 931, 'min_y': 150, 'max_x': 1240, 'm...   \n",
       "3  happiness  {'min_x': 929, 'min_y': 149, 'max_x': 1238, 'm...   \n",
       "4  happiness  {'min_x': 927, 'min_y': 149, 'max_x': 1236, 'm...   \n",
       "\n",
       "                                            img_path  \n",
       "0  /tf/notebooks/datasets/emotion/multi-modal/par...  \n",
       "1  /tf/notebooks/datasets/emotion/multi-modal/par...  \n",
       "2  /tf/notebooks/datasets/emotion/multi-modal/par...  \n",
       "3  /tf/notebooks/datasets/emotion/multi-modal/par...  \n",
       "4  /tf/notebooks/datasets/emotion/multi-modal/par...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tag_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9523d94278>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAElCAYAAAAC1F7cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHddJREFUeJzt3XuYXFWd7vHvy0VQuUvLAUIMOgEfQA2QA6igIAfkNoAeRRgUVDQ6wuP1nCM6zuDoMOM4Xo6OM2gcIzAjIIpIVFAj6jCoCAkiVxkCwpAYIYoCB/ACvOePvZpUQne6qrvTuzfr/TxPPVW1ateuX+fpzlt7r7XXkm0iIqJO67VdQEREtCchEBFRsYRARETFEgIRERVLCEREVCwhEBFRsYRARETFEgIRERVLCEREVGyDtgsYy9Zbb+1Zs2a1XUZERGcsWbLkV7aH+tl22ofArFmzWLx4cdtlRER0hqQ7+t02p4MiIiqWEIiIqFhCICKiYgmBiIiKJQQiIiqWEIiIqFhCICKiYgmBiIiKjRkCknaQ9D1JN0q6QdLbSvtWkhZJuqXcb1naJemTkpZKulbSHj37OrFsf4ukE9fdjxUREf3o54rhh4F32b5a0qbAEkmLgNcCl9r+kKRTgVOBdwOHArPLbW/gDGBvSVsBpwFzAZf9LLT9m8n8gWad+o3J3N1qbv/Q4ets3xERbRjzSMD2CttXl8f3AzcB2wNHAWeVzc4Cji6PjwLOduMKYAtJ2wIvBRbZvqf8x78IOGRSf5qIiBjIQH0CkmYBuwM/BraxvaK89Etgm/J4e+DOnrctK22jtY/0OfMkLZa0eOXKlYOUGBERA+g7BCRtAlwAvN32fb2v2TbNKZ5JYXu+7bm25w4N9TURXkREjENfISBpQ5oA+ILtr5Tmu8ppHsr93aV9ObBDz9tnlLbR2iMioiX9jA4S8DngJtsf63lpITA8wudE4KKe9hPKKKF9gHvLaaNvAQdL2rKMJDq4tEVEREv6GR30QuA1wHWSrilt7wU+BJwv6STgDuCY8trFwGHAUuBB4HUAtu+R9EHgqrLdB2zfMyk/RUREjMuYIWD7ckCjvHzgCNsbOHmUfS0AFgxSYERErDu5YjgiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYP8tLLpB0t6Tre9q+KOmacrt9eMUxSbMkPdTz2qd73rOnpOskLZX0ybJsZUREtKif5SXPBD4FnD3cYPtVw48lfRS4t2f7W23PGWE/ZwBvBH5MswTlIcAlg5ccERGTZcwjAduXASOuBVy+zR8DnLu2fUjaFtjM9hVl+cmzgaMHLzciIibTRPsE9gPusn1LT9uOkn4i6d8l7VfatgeW9WyzrLRFRESL+jkdtDbHsfpRwApgpu1fS9oT+KqkXQfdqaR5wDyAmTNnTrDEiIgYzbiPBCRtALwc+OJwm+3f2/51ebwEuBXYCVgOzOh5+4zSNiLb823PtT13aGhovCVGRMQYJnI66H8AP7P92GkeSUOS1i+PnwnMBm6zvQK4T9I+pR/hBOCiCXx2RERMgn6GiJ4L/AjYWdIySSeVl47l8R3CLwKuLUNGvwy82fZwp/JbgH8BltIcIWRkUEREy8bsE7B93Cjtrx2h7QLgglG2XwzsNmB9ERGxDuWK4YiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIivWzvOQCSXdLur6n7f2Slku6ptwO63ntPZKWSrpZ0kt72g8pbUslnTr5P0pERAyqnyOBM4FDRmj/uO055XYxgKRdaNYe3rW8558lrV8Wn/8n4FBgF+C4sm1ERLSonzWGL5M0q8/9HQWcZ/v3wM8lLQX2Kq8ttX0bgKTzyrY3DlxxRERMmon0CZwi6dpyumjL0rY9cGfPNstK22jtERHRovGGwBnAs4A5wArgo5NWESBpnqTFkhavXLlyMncdERE9xhUCtu+y/YjtR4HPsuqUz3Jgh55NZ5S20dpH2/9823Ntzx0aGhpPiRER0YdxhYCkbXuevgwYHjm0EDhW0kaSdgRmA1cCVwGzJe0o6Uk0nccLx192RERMhjE7hiWdC+wPbC1pGXAasL+kOYCB24E3Adi+QdL5NB2+DwMn236k7OcU4FvA+sAC2zdM+k8TERED6Wd00HEjNH9uLdufDpw+QvvFwMUDVRcREetUrhiOiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqNmYISFog6W5J1/e0/YOkn0m6VtKFkrYo7bMkPSTpmnL7dM979pR0naSlkj4pSevmR4qIiH71cyRwJnDIGm2LgN1sPxf4T+A9Pa/dantOub25p/0M4I006w7PHmGfERExxcYMAduXAfes0fZt2w+Xp1cAM9a2j7Iw/Wa2r7Bt4Gzg6PGVHBERk2Uy+gReD1zS83xHST+R9O+S9itt2wPLerZZVtoiIqJFYy40vzaS/gJ4GPhCaVoBzLT9a0l7Al+VtOs49jsPmAcwc+bMiZQYERFrMe4jAUmvBY4Aji+neLD9e9u/Lo+XALcCOwHLWf2U0YzSNiLb823PtT13aGhovCVGRMQYxhUCkg4B/g9wpO0He9qHJK1fHj+TpgP4NtsrgPsk7VNGBZ0AXDTh6iMiYkLGPB0k6Vxgf2BrScuA02hGA20ELCojPa8oI4FeBHxA0h+BR4E32x7uVH4LzUijJ9P0IfT2I0RERAvGDAHbx43Q/LlRtr0AuGCU1xYDuw1UXURErFO5YjgiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomIJgYiIiiUEIiIqlhCIiKhYQiAiomJ9hYCkBZLulnR9T9tWkhZJuqXcb1naJemTkpZKulbSHj3vObFsf4ukEyf/x4mIiEH0eyRwJnDIGm2nApfang1cWp4DHEqzwPxsYB5wBjShQbM+8d7AXsBpw8ERERHt6CsEbF8G3LNG81HAWeXxWcDRPe1nu3EFsIWkbYGXAots32P7N8AiHh8sERExhSbSJ7CN7RXl8S+Bbcrj7YE7e7ZbVtpGa4+IiJZMSsewbQOejH0BSJonabGkxStXrpys3UZExBomEgJ3ldM8lPu7S/tyYIee7WaUttHaH8f2fNtzbc8dGhqaQIkREbE2EwmBhcDwCJ8TgYt62k8oo4T2Ae4tp42+BRwsacvSIXxwaYuIiJZs0M9Gks4F9ge2lrSMZpTPh4DzJZ0E3AEcUza/GDgMWAo8CLwOwPY9kj4IXFW2+4DtNTubIyJiCvUVAraPG+WlA0fY1sDJo+xnAbCg7+oiImKdyhXDEREVSwhERFQsIRARUbGEQERExRICEREVSwhERFQsIRARUbGEQERExRICEREVSwhERFQsIRARUbGEQERExRICEREVSwhERFQsIRARUbGEQERExcYdApJ2lnRNz+0+SW+X9H5Jy3vaD+t5z3skLZV0s6SXTs6PEBER49XXymIjsX0zMAdA0vo0i8ZfSLOc5Mdtf6R3e0m7AMcCuwLbAd+RtJPtR8ZbQ0RETMxknQ46ELjV9h1r2eYo4Dzbv7f9c5o1iPeapM+PiIhxmKwQOBY4t+f5KZKulbRA0palbXvgzp5tlpW2iIhoyYRDQNKTgCOBL5WmM4Bn0ZwqWgF8dBz7nCdpsaTFK1eunGiJERExisk4EjgUuNr2XQC277L9iO1Hgc+y6pTPcmCHnvfNKG2PY3u+7bm25w4NDU1CiRERMZLJCIHj6DkVJGnbntdeBlxfHi8EjpW0kaQdgdnAlZPw+RERMU7jHh0EIOmpwEHAm3qaPyxpDmDg9uHXbN8g6XzgRuBh4OSMDIqIaNeEQsD2A8DT1mh7zVq2Px04fSKfGRERkydXDEdEVCwhEBFRsYRARETFEgIRERVLCEREVCwhEBFRsYRARETFEgIRERVLCEREVCwhEBFRsYRARETFEgIRERVLCEREVCwhEBFRsYRARETFEgIRERVLCEREVGzCISDpdknXSbpG0uLStpWkRZJuKfdblnZJ+qSkpZKulbTHRD8/IiLGb7KOBA6wPcf23PL8VOBS27OBS8tzgENpFpifDcwDzpikz4+IiHFYV6eDjgLOKo/PAo7uaT/bjSuALSRtu45qiIiIMUxGCBj4tqQlkuaVtm1sryiPfwlsUx5vD9zZ895lpS0iIlqwwSTsY1/byyU9HVgk6We9L9q2JA+ywxIm8wBmzpw5CSVGRMRIJnwkYHt5ub8buBDYC7hr+DRPub+7bL4c2KHn7TNK25r7nG97ru25Q0NDEy0xIiJGMaEQkPRUSZsOPwYOBq4HFgInls1OBC4qjxcCJ5RRQvsA9/acNoqIiCk20dNB2wAXShre1zm2vynpKuB8SScBdwDHlO0vBg4DlgIPAq+b4OdHRMQETCgEbN8GPG+E9l8DB47QbuDkiXxmRERMnlwxHBFRsYRARETFEgIRERVLCEREVCwhEBFRsYRARETFEgIRERVLCEREVCwhEBFRsYRARETFEgIRERVLCEREVCwhEBFRsYRARETFEgIRERVLCEREVCwhEBFRsXGHgKQdJH1P0o2SbpD0ttL+fknLJV1Tbof1vOc9kpZKulnSSyfjB4iIiPGbyPKSDwPvsn11WWx+iaRF5bWP2/5I78aSdgGOBXYFtgO+I2kn249MoIaIiJiAcR8J2F5h++ry+H7gJmD7tbzlKOA827+3/XOaxeb3Gu/nR0TExE1Kn4CkWcDuwI9L0ymSrpW0QNKWpW174M6ety1jlNCQNE/SYkmLV65cORklRkTECCYcApI2AS4A3m77PuAM4FnAHGAF8NFB92l7vu25tucODQ1NtMSIiBjFhEJA0oY0AfAF218BsH2X7UdsPwp8llWnfJYDO/S8fUZpi4iIlkxkdJCAzwE32f5YT/u2PZu9DLi+PF4IHCtpI0k7ArOBK8f7+RERMXETGR30QuA1wHWSrilt7wWOkzQHMHA78CYA2zdIOh+4kWZk0ckZGRQR0a5xh4DtywGN8NLFa3nP6cDp4/3MiIiYXLliOCKiYhM5HRSTbNap31in+7/9Q4ev0/1HRPckBGLSJMQiuiengyIiKpYQiIioWE4HRRQ5nRU1ypFARETFEgIRERVLCEREVCwhEBFRsYRARETFEgIRERVLCEREVCwhEBFRsYRARETFcsVwxBNErniO8ZjyIwFJh0i6WdJSSadO9edHRMQqU3okIGl94J+Ag4BlwFWSFtq+cSrriIjpJ0cy7Zjq00F7AUtt3wYg6TzgKJp1hyMiOmtdhti6DLCpPh20PXBnz/NlpS0iIlog21P3YdIrgENsv6E8fw2wt+1T1thuHjCvPN0ZuHkdlbQ18Kt1tO+pkPrblfrb1eX613Xtz7A91M+GU306aDmwQ8/zGaVtNbbnA/PXdTGSFtueu64/Z11J/e1K/e3qcv3TqfapPh10FTBb0o6SngQcCyyc4hoiIqKY0iMB2w9LOgX4FrA+sMD2DVNZQ0RErDLlF4vZvhi4eKo/dxTr/JTTOpb625X629Xl+qdN7VPaMRwREdNL5g6KiKhYQiAiomIJgYgKqLHD2FtGbdInEFNK0lOBh2w/Kmkn4NnAJbb/2HJpY5K0o+2fj9U2XUm6zvZz2q5jUJJevrbXbX9lqmqZLJK2BHawfW3rtdQSApLuB0b6YQXY9mZTXNK4SNoG+FtgO9uHStoFeL7tz7VcWl8kLQH2A7YEfkBz7cgfbB/famF9kHS17T3WaFtie8+2ahqEpLOAT9m+qu1aBiHp8+Xh04EXAN8tzw8Afmj7iFYKG5Ck7wNH0ozKXALcDfzA9jvbrKua9QRsb9p2DZPkTODzwF+U5/8JfBHoRAjQfPF4UNJJwD/b/rCka9ouam0kPRvYFdh8jW+lmwEbt1PVuOwNHC/pDuABVn0Bem67Za2d7dcBSPo2sIvtFeX5tjR/D12xue37JL0BONv2aZJaPxKoJgTWJOnp9PwB2/6vFssZxNa2z5f0HnjsArxH2i5qAJL0fOB44KTStn6L9fRjZ+AIYAvgT3va7wfe2EpF4/PStguYoB2GA6C4C5jZVjHjsEEJrmNY9SWuddWFgKQjgY8C29Ecjj0DuInmm14XPCDpaZRTW5L2Ae5tt6SBvB14D3Ch7RskPRP4Xss1rZXti4CLJD3f9o/arme8bN8haV9gtu3PSxoCNmm7rgFcKulbwLnl+auA77RYz6A+QDNbwuW2ryq/+7e0XFM9fQLDJP0UeAnwHdu7SzoAeLXtk8Z467QgaQ/gH4HdgOuBIeAV06GDaVCS1gM2sX1f27X0Q9KHgb8BHgK+CTwXeIftf2u1sD5JOg2YC+xseydJ2wFfsv3ClkvrWzkdt195epntC9us54mgxiGif7T9a2A9SevZ/h7NH0Yn2L4aeDFNB9mbgF27FACSzpG0WRkldD1wo6T/3XZdfTq4BNYRwO3AnwBdqR3gZTQdkw8A2P4F0Km+Mttfsf2OcutUAEj6cPnd31DSpZJWSnp123XVGAK/lbQJcBnwBUmfoPxRdIGkVwJPLhPvHQ18sRwddMUu5T/So4FLgB2B17RbUt82LPeH03yD7tJpOGhGYZlVpxKf2nI9fZF0ebm/X9J9Pbf7JXXiKLKYll8iagyBo4AHgXfQHNLfyuqdfdPdX9q+v5zbPZBmVNAZLdc0iA0lbUgTAgvL9QFdOSf5NUk/A/akOT89BPyu5ZoGcb6kzwBbSHojzfn0z7Zc05hs71vuN7W9Wc9t064M7S6G+2Cn1ZeIqvoEykL337F9QNu1jJekn5S+jL8DrrN9znBb27X1Q9JbgXcDP6X5Y5gJ/Jvt/db6xmlC0lbAvbYfkfQUYDPbv2y7rn5JOgg4mGZ46LdsL2q5pIF1dWSfpA/RfPl5iGa99S2Ar9veu9W6agoBAEmXAi+fLik8KElfp1mN7SBgD5pfqCttP6/VwiZA0ga2H267jrFIOmGkdttnT3UtNRptZJ/trozsW/NLxFOBTdv+ElHdEFHg/wHXSVpET1+A7be2V9JAjgEOAT5i+7dl3HHr5xX7NdoVz3TjYrf/3vN4Y5rTcVcDnQiBUa6avxdYDLzL9m1TX9VAPgjswxoj+1quqW/lyPEtNEe/82jCbGfg663WVeGRwIkjNHu6f5uTtFm52nCrkV63fc9U1zQeki6hXPFs+3mSNgB+0tE5bbYAzrN9SNu19EPSB4FlwDk0p4OOBZ5FE2R/bnv/9qob2/C6vGWY9+5l/qmfduUoWNIXaaaLOMH2biUUfmh7Tpt11XgksIXtT/Q2SHpbW8UM4ByaUQVLaL7Nqec1A89so6hx6PoVz70eoBnd1BVHrvEf5nxJ19h+t6T3tlZV/9Yc2Xc3HRrZBzzL9qskHQdQpk/RWG9a12oMgROBT6zR9toR2qYV20eUX5gXd6UjbBSdveJZ0tdYdTplPWAX4Pz2KhrYg5KOAb5cnr+CVaObunBK4CiaPrB30Ew7sjnNVbhd8QdJT2bV7/6zgN+3W1JFp4NK+v4ZsC/wHz0vbQo8avvAVgobkDo6HfCwLl/xLOnFPU8fBu6wvaytegZVpin4BE0fjIEraP5DXQ7safvyFstbqyfIyL6DgPfRfHn4NvBC4LW2v99qXRWFwDNoDt3/Dji156X7gWu7MDoFujsdcK/SD7AzzSmtm92BtQSifV0f2QdQjoL3ofndv8L2r1ouqZ4QeKIoFyv9CdCp6YB7SXoBMIue05HTvWMeuj+6plzc9kYe/2//+rZqGoSki4Ddga6O7EPS9jRDW3v//S9rr6IK+wTW+EN+Es1UAA906MrDTk8HLOlfaUakXAMMdwibbgyz/L+MPrpmAbB/a5X15yKaU6HfYdW/fZd8pdw6SdLf08x8egPwaGk2TUd3a6o+EigdrUcB+9g+daztp4tyXn1fml+gH5RJ5TpB0k008wd17hdvpOGIZXTNnC4MVRyute06BiXpUtsHSvp72+9uu57xknQz8FzbrXcG96px7qDHuPFVOvTtWtJfAWcBTwO2Bj4v6X3tVjWQ64H/1nYR4/SgpGMkrVdux9Ct0TVfl3RY20WMw7blFOKRknaXtEfvre3iBnAbqyYhnDaqOxLQ6ssDrkczjfSLbT+/pZIGUr5NPM/278rzJwPX2N653cr6I+l7wBzgSnqGx9k+srWi+rTG6BqAH9GR0TXw2KnQp9L8u/+RjqyvLekVNKvQ7UvT/9LLtl8y9VUNTtIFwPOAS1n9d7/VPo3q+gRYfcbQh2mmdD2qnVLG5Rc0UxYMfwPdiOY/oa54f9sFjFfp+B1txtlpHQDQzMJZrjifTYfWRrb9ZeDLkv4S+BSwE039XfsGu7DcppXqjgS6TtJXaeawWUTzR3AQzbfqZdD+t4onMnV/ZbE3AG8DZtB0zO9DM21BV66ReSPwVjpa/3RVXQhI2olm/v1tyvwdz6W5nP5vWi6tL6PMffQY22dNVS2DkHS57X1HGGbZiVMSsFon8MtopvB4J80Sh9O6Q3iYpOtovkBcUX6OZwN/a/vlY7x1Wuhq/aXuUf+jbXt4d42ngz5LM+vmZwBsXyvpHJpveNNauWryYNvHt13LoNyzMEjbtUzA4xYFmQZTvwzid7Z/JwlJG9n+maRO9CUVXa3/iHJ/crn/13L/aqbBKa0aQ+Aptq9c44+3E1cLlznInyHpSbb/0HY947XGENfLbf+k5ZL69fVysd5DwJ+reyuLLSszn34VWCTpNzQXHXZFJ+u3fQc000Z49cWf3i3palafwWDK1RgCvyoTNw1P4vQKYEW7JQ3kNuAHkhay+lWTH2uvpP6VIa6vZNVFP2dK+lIXTsfZPrX0CwwvCvIAHRpUYPtl5eH7yyitzWn6Njqh6/XTXJr0Qts/KE9ewDQYpl9jn8AzgfnAC4DfAD8Hjh9O6+lO0mkjtdv+66muZTy6OMRV0ktsf3eN4cWPsd3Zq1hj6kjak+bK8s1p+sJ+A7y+7Ys9azwSWE6zqMn3gK2A+2iml+7ElLRd+c9+Lbo4xPVFwHdphocOr+XQe58QiDHZXgI8T9Lm5fm0mAivxhC4CPgtzXwvv2i5loGVw+DHHb515YIZmgnXblCzvOdjQ1wlfRKm7RDX+yW9k+Zq594Ffeo6jI4Jk3Q4sCuw8XC/pO1Wv4DWGAIzurIc4Cj+V8/jjYH/SUc6tosLy23Y91uqYxCblPudaYYoXkQTBH9Kc41GxJgkfRp4CnAA8C80i/q0/vtTY5/AfOAfbV/Xdi2TRdKVtvdqu45+SXoS8Gyab9I3d2Wkk6TLgMNt31+ebwp8w/aL2q0sukDStbaf23O/CXCJ7f3arKvGI4F9gddK+jnN/B2dmo9fqy80Pzz30eYtlTOwMoHZZ4Bbaf7td5T0JtuXtFtZX7YBegPrD6Utoh/D/WAPStoOuAfYtsV6gDpD4NC2C5ig3oXm/0gz99FJbRY0oI8BB9heCo+ts/oNoAshcDZN/8Xw6ayjgTPbKyc65mvlOod/oOmTNM3Fq62qLgS6MhR0Ld4NfNP2fWVCrT2AB1uuaRD3DwdAcRvNEp/Tnu3TJV0CDB++v65DF7pF+34GPGL7Akm70PztfrXlmurrE+i6nvOJ+wIfBD4C/JXtvVsurS+SzqBZXu98mm9CrwT+i2a1q4y5jyes6fq32/rVajGw4WUBDwc+a/sbNMtkdsXGwF3Ai2mWY1wJPJlmpM0Ro78tovOm5d9ujgQ6RtLXaS6uOojmcPIh4MquzGQZUavp+rebEOgYSU8BDgGus32LpG2B59j+dsul9UXSxjQd2bvSs7CJ7de3VlTEFJiuf7sJgZhSkr5E00H2ZzRTdRwP3GT7ba0WFlGphEBMKUk/sb17TyfZhsB/2N6n7doiapSO4Zhqfyz3v5W0G82Fbk9vsZ6IqlV3nUC0br6kLYH30Sy6vQnwl+2WFFGvnA6KKSVpI5pJ72YBG5Zmtz2TYkStciQQU+0imumkl9DM3RQRLcqRQEwpSdfb3q3tOiKikY7hmGo/lPSctouIiEaOBGJKSLqOZq6gDYDZNBPHdW4q74gnmoRATAlJz1jb60+A2V0jOikhEBFRsfQJRERULCEQEVGxhEBERMUSAhERFUsIRERU7P8DnzUryNLDyrsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_tag_info_df[\"emotion\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      2026\n",
       "surprise      190\n",
       "happiness     179\n",
       "disgust       143\n",
       "anger          52\n",
       "afraid         26\n",
       "sadness        20\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tag_info_df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing sampling\n",
    "\n",
    "## disgust와 contempt는 disgust 하나로 합침\n",
    "# raw_tag_info_df[raw_tag_info_df[\"emotions\"]=='contempt'] = 'disgust'\n",
    "raw_tag_info_df = raw_tag_info_df.replace('contempt', 'disgust')\n",
    "\n",
    "\n",
    "min_emotion_cnt = np.min(raw_tag_info_df[\"emotion\"].value_counts())\n",
    "sampled_tag_info_df = raw_tag_info_df.groupby(\"emotion\", group_keys=False).apply(lambda df: df.sample(min_emotion_cnt))\n",
    "sampled_tag_info_df = sampled_tag_info_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger        20\n",
       "afraid       20\n",
       "neutral      20\n",
       "disgust      20\n",
       "sadness      20\n",
       "happiness    20\n",
       "surprise     20\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_tag_info_df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion      140\n",
       "face_rect    140\n",
       "img_path     140\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_tag_info_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time Convolutional Neural Networks for Emotion and Gender Classification 모델을 위한 전처리 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "num_cores = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_path_to_pixel(x):\n",
    "    \n",
    "    img_path, face_rect = x[0], x[1]\n",
    "    \n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_shape = img.shape\n",
    "    \n",
    "    # face_rect 부분 잘라내기\n",
    "    # ex) 'max_x': 1125, 'max_y': 798, 'min_x': 708, 'min_y': 267\n",
    "    min_x = face_rect['min_x']\n",
    "    max_x = face_rect['max_x']\n",
    "    min_y = face_rect['min_y']\n",
    "    max_y = face_rect['max_y']\n",
    "    \n",
    "    if  not isinstance(min_x, int) or not isinstance(max_x, int) or  not isinstance(min_y, int) or not isinstance(max_y, int) or \\\n",
    "        min_x <= 0 or max_x <= 0 or min_y <= 0 or max_y <= 0:\n",
    "        return None\n",
    "    \n",
    "#     print(min_y,max_y, min_x,max_x)\n",
    "    img = img[min_y:max_y, min_x:max_x]\n",
    "    \n",
    "    # 이미지 축소 시에는 INTER_AREA, https://076923.github.io/posts/Python-opencv-8/\n",
    "    img = cv2.resize(img, dsize=(48, 48), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # split array to ' ' str\n",
    "    img = ' '.join(img.astype(int).astype(str).reshape(-1))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_process_sub(df_split):\n",
    "\n",
    "    return df_split[['img_path', 'face_rect']].apply(img_path_to_pixel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_process(df, func):\n",
    "    df_split = np.array_split(df, num_cores)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time sampled_tag_info_df['img_path_new'] = sampled_tag_info_df[['img_path','face_rect']].apply(img_path_to_pixel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.4 ms, sys: 373 ms, total: 419 ms\n",
      "Wall time: 894 ms\n"
     ]
    }
   ],
   "source": [
    "%time sampled_tag_info_df['img_path_new'] = multi_process(sampled_tag_info_df, multi_process_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상 데이터 drop\n",
    "sampled_tag_info_df = sampled_tag_info_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f951e531668>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.asarray(sampled_tag_info_df.loc[0]['img_path_new'].split(' ')).astype(int).reshape((48,48)), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_tag_info_df['img_path'] = sampled_tag_info_df['img_path_new']\n",
    "prep_tag_info_df = sampled_tag_info_df.drop(['img_path_new', 'face_rect'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afraid</td>\n",
       "      <td>85 89 98 96 83 73 59 43 30 26 25 24 28 29 26 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afraid</td>\n",
       "      <td>89 88 84 86 84 75 51 45 34 35 38 40 38 31 32 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afraid</td>\n",
       "      <td>72 70 78 74 73 61 45 42 37 37 36 38 45 73 57 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afraid</td>\n",
       "      <td>72 70 68 76 77 76 58 48 47 44 36 29 42 72 49 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afraid</td>\n",
       "      <td>77 80 81 71 54 47 43 40 35 34 51 79 48 44 50 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion                                           img_path\n",
       "0  afraid  85 89 98 96 83 73 59 43 30 26 25 24 28 29 26 2...\n",
       "1  afraid  89 88 84 86 84 75 51 45 34 35 38 40 38 31 32 5...\n",
       "2  afraid  72 70 78 74 73 61 45 42 37 37 36 38 45 73 57 4...\n",
       "3  afraid  72 70 68 76 77 76 58 48 47 44 36 29 42 72 49 3...\n",
       "4  afraid  77 80 81 71 54 47 43 40 35 34 51 79 48 44 50 5..."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_tag_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 step 2\n",
    "\n",
    "* CSV dataset file 생성\n",
    "    * 포멧: emotion\n",
    "    * emotion mapping\n",
    "        * ASIS: 8 Catogory ('happiness', 'afraid', 'neutral', 'surprise', 'sadness', 'contempt', 'anger', 'disgust')\n",
    "        * TO: 7 Category  (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "        * mapped Category: 0=anger, 1=disgust&contempt, 2=afraid, 3=happiness, 4=sadness, 5=surprise, 6=neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_mapping(emotion):\n",
    "    if emotion == 'anger':\n",
    "        return 0\n",
    "    elif emotion == 'disgust' or emotion == 'contempt':\n",
    "        return 1\n",
    "    elif emotion == 'afraid':\n",
    "        return 2\n",
    "    elif emotion == 'happiness':\n",
    "        return 3\n",
    "    elif emotion == 'sadness':\n",
    "        return 4\n",
    "    elif emotion == 'surprise':\n",
    "        return 5\n",
    "    elif emotion == 'neutral':\n",
    "        return 6\n",
    "    else:\n",
    "        return 6\n",
    "        \n",
    "\n",
    "prep_tag_info_df['mapped_emotion'] = prep_tag_info_df['emotion'].map(emotion_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    20\n",
       "3    20\n",
       "2    20\n",
       "0    20\n",
       "6    19\n",
       "4    15\n",
       "1    15\n",
       "Name: mapped_emotion, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_tag_info_df['mapped_emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>85 89 98 96 83 73 59 43 30 26 25 24 28 29 26 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>89 88 84 86 84 75 51 45 34 35 38 40 38 31 32 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72 70 78 74 73 61 45 42 37 37 36 38 45 73 57 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>72 70 68 76 77 76 58 48 47 44 36 29 42 72 49 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>77 80 81 71 54 47 43 40 35 34 51 79 48 44 50 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                           img_path\n",
       "0        2  85 89 98 96 83 73 59 43 30 26 25 24 28 29 26 2...\n",
       "1        2  89 88 84 86 84 75 51 45 34 35 38 40 38 31 32 5...\n",
       "2        2  72 70 78 74 73 61 45 42 37 37 36 38 45 73 57 4...\n",
       "3        2  72 70 68 76 77 76 58 48 47 44 36 29 42 72 49 3...\n",
       "4        2  77 80 81 71 54 47 43 40 35 34 51 79 48 44 50 5..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_tag_info_df['emotion'] = prep_tag_info_df['mapped_emotion']\n",
    "prep_tag_info_df = prep_tag_info_df.drop(['mapped_emotion'], axis=1)\n",
    "prep_tag_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alh ../datasets/kor_multi_modal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_tag_info_df.to_csv(prep_trainset_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(prep_trainset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.9G\r\n",
      "drwxr-xr-x 3 root root  157 Jul  6 19:15 .\r\n",
      "drwxr-xr-x 4 root root  104 Jun 30 09:50 ..\r\n",
      "drwxr-xr-x 2 root root  12K Jun 30 09:50 part1\r\n",
      "-rw-r--r-- 1 root root 240M Jul  6 18:18 prep_part1.csv\r\n",
      "-rw-r--r-- 1 root root 415M Jul  6 18:31 prep_part2.csv\r\n",
      "-rw-r--r-- 1 root root 464M Jul  6 18:38 prep_part3.csv\r\n",
      "-rw-r--r-- 1 root root 476M Jul  6 18:42 prep_part4.csv\r\n",
      "-rw-r--r-- 1 root root 267M Jul  6 19:15 prep_part5.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ../datasets/kor_multi_modal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rt-face-detect",
   "language": "python",
   "name": "rt-face-detect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
